{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696e901a-0c32-4a8e-aab5-14b0504012d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.metrics import Precision, Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0b87d1-5500-4db1-ae9a-6116dd8d952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory and paths for training and testing\n",
    "base_dir = r'C:\\Users\\ASUS\\OneDrive\\Desktop\\fyp2\\datasets\\apple_disease_classification'\n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e639ce2-0f6f-47d5-b218-384014b89de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1280 images belonging to 4 classes.\n",
      "Found 319 images belonging to 4 classes.\n",
      "Found 600 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up data augmentation for training with a validation split.\n",
    "# Adjusted augmentation parameters to be slightly less aggressive.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,         # Reduced rotation range (was 40)\n",
    "    width_shift_range=0.1,     # Reduced horizontal shift (was 0.2)\n",
    "    height_shift_range=0.1,    # Reduced vertical shift (was 0.2)\n",
    "    shear_range=0.1,           # Reduced shear (was 0.2)\n",
    "    zoom_range=0.1,            # Reduced zoom (was 0.2)\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2       # Reserve 20% of training data for validation\n",
    ")\n",
    "\n",
    "# Data generator for test data (only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),    # Resize images to 150x150\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Create validation data generator\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Create test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b0e768-3585-47f6-b7e2-0d6e13bf4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "# Early stopping to halt training if the model stops improving on validation data.\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Model checkpoint to save the best model based on validation accuracy.\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving.\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027ec866-bcac-4a16-a450-02895c8005c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Custom Callback to Store Learning Rate\n",
    "class LearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.learning_rate)\n",
    "\n",
    "# ✅ Add the Callback to Your Callbacks List\n",
    "lr_tracker = LearningRateTracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9206fd-8ea4-4186-85d4-82c5c89cd127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">18,940,416</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │      \u001b[38;5;34m18,940,416\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m2,052\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,038,660</span> (72.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,038,660\u001b[0m (72.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,037,188</span> (72.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,037,188\u001b[0m (72.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> (5.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,472\u001b[0m (5.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the custom CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(150, 150, 3)),\n",
    "\n",
    "    # Convolutional Block 1 with L2 regularization\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.15),\n",
    "\n",
    "    # Convolutional Block 2 with L2 regularization\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Convolutional Block 3 with L2 regularization\n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    # Flatten and Fully Connected Layers with L2 regularization\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# ✅ Compile the Model with Additional Metrics\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b82552c-89c0-4c1e-a489-8189856787c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\OneDrive\\Desktop\\fyp2\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "C:\\Users\\ASUS\\OneDrive\\Desktop\\fyp2\\venv\\Lib\\site-packages\\PIL\\Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5401 - loss: 3.4597 - precision: 0.5525 - recall: 0.5175  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\OneDrive\\Desktop\\fyp2\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.25078, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.5415 - loss: 3.4498 - precision: 0.5539 - recall: 0.5189 - val_accuracy: 0.2508 - val_loss: 9.1182 - val_precision: 0.2508 - val_recall: 0.2508 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6361 - loss: 2.8911 - precision: 0.6646 - recall: 0.6188  \n",
      "Epoch 2: val_accuracy did not improve from 0.25078\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.6361 - loss: 2.8906 - precision: 0.6645 - recall: 0.6187 - val_accuracy: 0.2508 - val_loss: 4.3683 - val_precision: 0.2508 - val_recall: 0.2508 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6993 - loss: 2.7198 - precision: 0.7180 - recall: 0.6642  \n",
      "Epoch 3: val_accuracy did not improve from 0.25078\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.6986 - loss: 2.7219 - precision: 0.7173 - recall: 0.6636 - val_accuracy: 0.2508 - val_loss: 4.5397 - val_precision: 0.2524 - val_recall: 0.2508 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6922 - loss: 2.6487 - precision: 0.7107 - recall: 0.6683  \n",
      "Epoch 4: val_accuracy improved from 0.25078 to 0.25392, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.6921 - loss: 2.6493 - precision: 0.7106 - recall: 0.6681 - val_accuracy: 0.2539 - val_loss: 5.2538 - val_precision: 0.2539 - val_recall: 0.2539 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7329 - loss: 2.4836 - precision: 0.7590 - recall: 0.7149  \n",
      "Epoch 5: val_accuracy did not improve from 0.25392\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.7324 - loss: 2.4845 - precision: 0.7584 - recall: 0.7143 - val_accuracy: 0.2539 - val_loss: 4.6703 - val_precision: 0.2539 - val_recall: 0.2539 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7246 - loss: 2.4637 - precision: 0.7502 - recall: 0.7069  \n",
      "Epoch 6: val_accuracy improved from 0.25392 to 0.26332, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.7243 - loss: 2.4624 - precision: 0.7500 - recall: 0.7066 - val_accuracy: 0.2633 - val_loss: 4.1768 - val_precision: 0.2633 - val_recall: 0.2633 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7475 - loss: 2.2546 - precision: 0.7571 - recall: 0.7251  \n",
      "Epoch 7: val_accuracy did not improve from 0.26332\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.7474 - loss: 2.2544 - precision: 0.7571 - recall: 0.7250 - val_accuracy: 0.2571 - val_loss: 4.3212 - val_precision: 0.2587 - val_recall: 0.2571 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7658 - loss: 2.0918 - precision: 0.7829 - recall: 0.7470  \n",
      "Epoch 8: val_accuracy improved from 0.26332 to 0.33229, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.7655 - loss: 2.0917 - precision: 0.7827 - recall: 0.7466 - val_accuracy: 0.3323 - val_loss: 4.1892 - val_precision: 0.3354 - val_recall: 0.3323 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7755 - loss: 2.0474 - precision: 0.7863 - recall: 0.7429  \n",
      "Epoch 9: val_accuracy improved from 0.33229 to 0.33856, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.7752 - loss: 2.0473 - precision: 0.7860 - recall: 0.7426 - val_accuracy: 0.3386 - val_loss: 4.0233 - val_precision: 0.3408 - val_recall: 0.3354 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7405 - loss: 2.0135 - precision: 0.7649 - recall: 0.7148  \n",
      "Epoch 10: val_accuracy improved from 0.33856 to 0.48589, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.7404 - loss: 2.0124 - precision: 0.7648 - recall: 0.7147 - val_accuracy: 0.4859 - val_loss: 2.6322 - val_precision: 0.5275 - val_recall: 0.4514 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7739 - loss: 1.8632 - precision: 0.7916 - recall: 0.7442  \n",
      "Epoch 11: val_accuracy improved from 0.48589 to 0.56113, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.7738 - loss: 1.8627 - precision: 0.7916 - recall: 0.7442 - val_accuracy: 0.5611 - val_loss: 2.3308 - val_precision: 0.5679 - val_recall: 0.5110 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7676 - loss: 1.7871 - precision: 0.7883 - recall: 0.7410  \n",
      "Epoch 12: val_accuracy improved from 0.56113 to 0.70219, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.7679 - loss: 1.7859 - precision: 0.7887 - recall: 0.7413 - val_accuracy: 0.7022 - val_loss: 2.0294 - val_precision: 0.7018 - val_recall: 0.6270 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7963 - loss: 1.6681 - precision: 0.8144 - recall: 0.7722  \n",
      "Epoch 13: val_accuracy did not improve from 0.70219\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.7961 - loss: 1.6681 - precision: 0.8143 - recall: 0.7720 - val_accuracy: 0.5110 - val_loss: 2.1345 - val_precision: 0.5702 - val_recall: 0.4326 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7729 - loss: 1.6222 - precision: 0.7969 - recall: 0.7530  \n",
      "Epoch 14: val_accuracy did not improve from 0.70219\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.7724 - loss: 1.6236 - precision: 0.7964 - recall: 0.7524 - val_accuracy: 0.6834 - val_loss: 1.9274 - val_precision: 0.7206 - val_recall: 0.6144 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8049 - loss: 1.5880 - precision: 0.8211 - recall: 0.7817  \n",
      "Epoch 15: val_accuracy improved from 0.70219 to 0.76176, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.8046 - loss: 1.5887 - precision: 0.8208 - recall: 0.7815 - val_accuracy: 0.7618 - val_loss: 1.6829 - val_precision: 0.7909 - val_recall: 0.7116 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7651 - loss: 1.6874 - precision: 0.7909 - recall: 0.7400  \n",
      "Epoch 16: val_accuracy did not improve from 0.76176\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.7651 - loss: 1.6872 - precision: 0.7908 - recall: 0.7400 - val_accuracy: 0.4953 - val_loss: 2.5105 - val_precision: 0.5169 - val_recall: 0.4796 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7732 - loss: 1.6018 - precision: 0.7979 - recall: 0.7471  \n",
      "Epoch 17: val_accuracy did not improve from 0.76176\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.7734 - loss: 1.6014 - precision: 0.7981 - recall: 0.7472 - val_accuracy: 0.6238 - val_loss: 1.9815 - val_precision: 0.6520 - val_recall: 0.6050 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7937 - loss: 1.4995 - precision: 0.8276 - recall: 0.7729  \n",
      "Epoch 18: val_accuracy improved from 0.76176 to 0.78056, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.7933 - loss: 1.5015 - precision: 0.8271 - recall: 0.7723 - val_accuracy: 0.7806 - val_loss: 1.5655 - val_precision: 0.7973 - val_recall: 0.7524 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8145 - loss: 1.4900 - precision: 0.8248 - recall: 0.7800  \n",
      "Epoch 19: val_accuracy did not improve from 0.78056\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.8140 - loss: 1.4906 - precision: 0.8245 - recall: 0.7795 - val_accuracy: 0.7147 - val_loss: 1.7947 - val_precision: 0.7336 - val_recall: 0.6991 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7655 - loss: 1.5211 - precision: 0.7892 - recall: 0.7385  \n",
      "Epoch 20: val_accuracy did not improve from 0.78056\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.7660 - loss: 1.5208 - precision: 0.7896 - recall: 0.7390 - val_accuracy: 0.7116 - val_loss: 1.6184 - val_precision: 0.7500 - val_recall: 0.6771 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8048 - loss: 1.4750 - precision: 0.8281 - recall: 0.7713  \n",
      "Epoch 21: val_accuracy improved from 0.78056 to 0.82759, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.8050 - loss: 1.4746 - precision: 0.8282 - recall: 0.7715 - val_accuracy: 0.8276 - val_loss: 1.4087 - val_precision: 0.8517 - val_recall: 0.7743 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8266 - loss: 1.4047 - precision: 0.8345 - recall: 0.8015  \n",
      "Epoch 22: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.8262 - loss: 1.4048 - precision: 0.8343 - recall: 0.8011 - val_accuracy: 0.8025 - val_loss: 1.4275 - val_precision: 0.8362 - val_recall: 0.7680 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8163 - loss: 1.4083 - precision: 0.8342 - recall: 0.7968  \n",
      "Epoch 23: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.8165 - loss: 1.4085 - precision: 0.8344 - recall: 0.7969 - val_accuracy: 0.7367 - val_loss: 1.6567 - val_precision: 0.7583 - val_recall: 0.7179 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7913 - loss: 1.4244 - precision: 0.8099 - recall: 0.7699  \n",
      "Epoch 24: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.7916 - loss: 1.4242 - precision: 0.8103 - recall: 0.7701 - val_accuracy: 0.6614 - val_loss: 1.9034 - val_precision: 0.6846 - val_recall: 0.6395 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8147 - loss: 1.4567 - precision: 0.8344 - recall: 0.7925  \n",
      "Epoch 25: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.8146 - loss: 1.4562 - precision: 0.8343 - recall: 0.7924 - val_accuracy: 0.6928 - val_loss: 1.7877 - val_precision: 0.7082 - val_recall: 0.6771 - learning_rate: 0.0010 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8030 - loss: 1.4461 - precision: 0.8259 - recall: 0.7890  \n",
      "Epoch 26: val_accuracy did not improve from 0.82759\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.8030 - loss: 1.4455 - precision: 0.8260 - recall: 0.7890 - val_accuracy: 0.8213 - val_loss: 1.4793 - val_precision: 0.8477 - val_recall: 0.8025 - learning_rate: 0.0010 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8295 - loss: 1.3566 - precision: 0.8420 - recall: 0.8005  \n",
      "Epoch 27: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.8297 - loss: 1.3559 - precision: 0.8423 - recall: 0.8008 - val_accuracy: 0.8119 - val_loss: 1.3513 - val_precision: 0.8283 - val_recall: 0.7712 - learning_rate: 5.0000e-04 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8310 - loss: 1.2647 - precision: 0.8491 - recall: 0.8120  \n",
      "Epoch 28: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8311 - loss: 1.2643 - precision: 0.8493 - recall: 0.8123 - val_accuracy: 0.6082 - val_loss: 2.0459 - val_precision: 0.6246 - val_recall: 0.5893 - learning_rate: 5.0000e-04 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8519 - loss: 1.1962 - precision: 0.8667 - recall: 0.8372  \n",
      "Epoch 29: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8517 - loss: 1.1967 - precision: 0.8666 - recall: 0.8370 - val_accuracy: 0.7179 - val_loss: 1.4883 - val_precision: 0.7313 - val_recall: 0.6740 - learning_rate: 5.0000e-04 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8751 - loss: 1.1255 - precision: 0.8878 - recall: 0.8613  \n",
      "Epoch 30: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.8747 - loss: 1.1261 - precision: 0.8875 - recall: 0.8608 - val_accuracy: 0.8245 - val_loss: 1.2324 - val_precision: 0.8421 - val_recall: 0.8025 - learning_rate: 5.0000e-04 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8640 - loss: 1.0981 - precision: 0.8782 - recall: 0.8407  \n",
      "Epoch 31: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8639 - loss: 1.0985 - precision: 0.8781 - recall: 0.8407 - val_accuracy: 0.7931 - val_loss: 1.2865 - val_precision: 0.8154 - val_recall: 0.7618 - learning_rate: 5.0000e-04 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8729 - loss: 1.0668 - precision: 0.8866 - recall: 0.8582  \n",
      "Epoch 32: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8725 - loss: 1.0675 - precision: 0.8861 - recall: 0.8578 - val_accuracy: 0.7962 - val_loss: 1.2546 - val_precision: 0.8249 - val_recall: 0.7680 - learning_rate: 5.0000e-04 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8406 - loss: 1.1069 - precision: 0.8599 - recall: 0.8237  \n",
      "Epoch 33: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.8410 - loss: 1.1064 - precision: 0.8601 - recall: 0.8241 - val_accuracy: 0.7806 - val_loss: 1.3164 - val_precision: 0.8013 - val_recall: 0.7461 - learning_rate: 5.0000e-04 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8810 - loss: 1.0455 - precision: 0.8971 - recall: 0.8576  \n",
      "Epoch 34: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8809 - loss: 1.0455 - precision: 0.8969 - recall: 0.8575 - val_accuracy: 0.7022 - val_loss: 1.5720 - val_precision: 0.7096 - val_recall: 0.6740 - learning_rate: 5.0000e-04 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8515 - loss: 1.1504 - precision: 0.8668 - recall: 0.8320  \n",
      "Epoch 35: val_accuracy did not improve from 0.82759\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.8511 - loss: 1.1511 - precision: 0.8665 - recall: 0.8316 - val_accuracy: 0.7618 - val_loss: 1.3490 - val_precision: 0.7919 - val_recall: 0.7398 - learning_rate: 5.0000e-04 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8458 - loss: 1.1264 - precision: 0.8694 - recall: 0.8206  \n",
      "Epoch 36: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8461 - loss: 1.1254 - precision: 0.8696 - recall: 0.8210 - val_accuracy: 0.6834 - val_loss: 1.5201 - val_precision: 0.7075 - val_recall: 0.6520 - learning_rate: 2.5000e-04 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8886 - loss: 1.0428 - precision: 0.9038 - recall: 0.8766  \n",
      "Epoch 37: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8885 - loss: 1.0428 - precision: 0.9037 - recall: 0.8765 - val_accuracy: 0.6865 - val_loss: 1.4686 - val_precision: 0.7081 - val_recall: 0.6614 - learning_rate: 2.5000e-04 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8732 - loss: 1.0846 - precision: 0.8896 - recall: 0.8573  \n",
      "Epoch 38: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.8733 - loss: 1.0833 - precision: 0.8897 - recall: 0.8574 - val_accuracy: 0.5361 - val_loss: 2.1300 - val_precision: 0.5362 - val_recall: 0.5110 - learning_rate: 2.5000e-04 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8749 - loss: 0.9905 - precision: 0.8896 - recall: 0.8620  \n",
      "Epoch 39: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8749 - loss: 0.9902 - precision: 0.8896 - recall: 0.8619 - val_accuracy: 0.7053 - val_loss: 1.4190 - val_precision: 0.7175 - val_recall: 0.6928 - learning_rate: 2.5000e-04 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8930 - loss: 0.9263 - precision: 0.9004 - recall: 0.8832  \n",
      "Epoch 40: val_accuracy did not improve from 0.82759\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8931 - loss: 0.9264 - precision: 0.9005 - recall: 0.8833 - val_accuracy: 0.6301 - val_loss: 1.6550 - val_precision: 0.6282 - val_recall: 0.6144 - learning_rate: 2.5000e-04 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9184 - loss: 0.8791 - precision: 0.9308 - recall: 0.9037  \n",
      "Epoch 41: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9182 - loss: 0.8794 - precision: 0.9306 - recall: 0.9036 - val_accuracy: 0.7367 - val_loss: 1.2736 - val_precision: 0.7605 - val_recall: 0.7367 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9059 - loss: 0.8926 - precision: 0.9200 - recall: 0.8851  \n",
      "Epoch 42: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9059 - loss: 0.8924 - precision: 0.9199 - recall: 0.8852 - val_accuracy: 0.7868 - val_loss: 1.1145 - val_precision: 0.8094 - val_recall: 0.7586 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9099 - loss: 0.8505 - precision: 0.9157 - recall: 0.8913  \n",
      "Epoch 43: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9100 - loss: 0.8503 - precision: 0.9159 - recall: 0.8914 - val_accuracy: 0.7994 - val_loss: 1.1541 - val_precision: 0.8084 - val_recall: 0.7806 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9162 - loss: 0.8087 - precision: 0.9252 - recall: 0.9017  \n",
      "Epoch 44: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9161 - loss: 0.8088 - precision: 0.9251 - recall: 0.9017 - val_accuracy: 0.8276 - val_loss: 1.0505 - val_precision: 0.8387 - val_recall: 0.8150 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9064 - loss: 0.8227 - precision: 0.9159 - recall: 0.8925  \n",
      "Epoch 45: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9066 - loss: 0.8225 - precision: 0.9160 - recall: 0.8926 - val_accuracy: 0.8276 - val_loss: 0.9983 - val_precision: 0.8344 - val_recall: 0.8056 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9143 - loss: 0.7991 - precision: 0.9257 - recall: 0.8993  \n",
      "Epoch 46: val_accuracy did not improve from 0.82759\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9144 - loss: 0.7989 - precision: 0.9258 - recall: 0.8994 - val_accuracy: 0.8182 - val_loss: 1.0607 - val_precision: 0.8328 - val_recall: 0.8119 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9075 - loss: 0.7971 - precision: 0.9127 - recall: 0.8979  \n",
      "Epoch 47: val_accuracy improved from 0.82759 to 0.87461, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9075 - loss: 0.7971 - precision: 0.9127 - recall: 0.8979 - val_accuracy: 0.8746 - val_loss: 0.8987 - val_precision: 0.8990 - val_recall: 0.8652 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9350 - loss: 0.7513 - precision: 0.9429 - recall: 0.9218  \n",
      "Epoch 48: val_accuracy did not improve from 0.87461\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9348 - loss: 0.7515 - precision: 0.9427 - recall: 0.9216 - val_accuracy: 0.8401 - val_loss: 0.9728 - val_precision: 0.8521 - val_recall: 0.8307 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9262 - loss: 0.7321 - precision: 0.9363 - recall: 0.9230  \n",
      "Epoch 49: val_accuracy did not improve from 0.87461\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9261 - loss: 0.7323 - precision: 0.9362 - recall: 0.9229 - val_accuracy: 0.8245 - val_loss: 0.9979 - val_precision: 0.8339 - val_recall: 0.8182 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9471 - loss: 0.6975 - precision: 0.9524 - recall: 0.9383  \n",
      "Epoch 50: val_accuracy improved from 0.87461 to 0.88401, saving model to best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9467 - loss: 0.6982 - precision: 0.9519 - recall: 0.9378 - val_accuracy: 0.8840 - val_loss: 0.8678 - val_precision: 0.8900 - val_recall: 0.8621 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9201 - loss: 0.7383 - precision: 0.9244 - recall: 0.9089  \n",
      "Epoch 51: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9202 - loss: 0.7381 - precision: 0.9246 - recall: 0.9090 - val_accuracy: 0.8652 - val_loss: 0.9235 - val_precision: 0.8698 - val_recall: 0.8589 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9429 - loss: 0.6880 - precision: 0.9493 - recall: 0.9331  \n",
      "Epoch 52: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9427 - loss: 0.6884 - precision: 0.9492 - recall: 0.9329 - val_accuracy: 0.8589 - val_loss: 0.8850 - val_precision: 0.8714 - val_recall: 0.8495 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9259 - loss: 0.7029 - precision: 0.9358 - recall: 0.9137  \n",
      "Epoch 53: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.9259 - loss: 0.7029 - precision: 0.9358 - recall: 0.9137 - val_accuracy: 0.7304 - val_loss: 1.1965 - val_precision: 0.7293 - val_recall: 0.7179 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9404 - loss: 0.6896 - precision: 0.9468 - recall: 0.9317  \n",
      "Epoch 54: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.9402 - loss: 0.6897 - precision: 0.9467 - recall: 0.9315 - val_accuracy: 0.8464 - val_loss: 0.9512 - val_precision: 0.8526 - val_recall: 0.8339 - learning_rate: 1.2500e-04 - lr: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9314 - loss: 0.6781 - precision: 0.9405 - recall: 0.9272  \n",
      "Epoch 55: val_accuracy did not improve from 0.88401\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9311 - loss: 0.6789 - precision: 0.9401 - recall: 0.9268 - val_accuracy: 0.8339 - val_loss: 0.9055 - val_precision: 0.8479 - val_recall: 0.8213 - learning_rate: 1.2500e-04 - lr: 6.2500e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9343 - loss: 0.6787 - precision: 0.9422 - recall: 0.9231  \n",
      "Epoch 56: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.9342 - loss: 0.6788 - precision: 0.9422 - recall: 0.9231 - val_accuracy: 0.8621 - val_loss: 0.8994 - val_precision: 0.8722 - val_recall: 0.8558 - learning_rate: 6.2500e-05 - lr: 6.2500e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9255 - loss: 0.6843 - precision: 0.9377 - recall: 0.9216  \n",
      "Epoch 57: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9257 - loss: 0.6839 - precision: 0.9379 - recall: 0.9217 - val_accuracy: 0.8245 - val_loss: 0.9688 - val_precision: 0.8317 - val_recall: 0.8213 - learning_rate: 6.2500e-05 - lr: 6.2500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9425 - loss: 0.6558 - precision: 0.9486 - recall: 0.9376  \n",
      "Epoch 58: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9426 - loss: 0.6554 - precision: 0.9486 - recall: 0.9376 - val_accuracy: 0.8433 - val_loss: 0.9218 - val_precision: 0.8498 - val_recall: 0.8339 - learning_rate: 6.2500e-05 - lr: 6.2500e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9522 - loss: 0.6127 - precision: 0.9557 - recall: 0.9467  \n",
      "Epoch 59: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9519 - loss: 0.6133 - precision: 0.9554 - recall: 0.9464 - val_accuracy: 0.7962 - val_loss: 1.0208 - val_precision: 0.8006 - val_recall: 0.7931 - learning_rate: 6.2500e-05 - lr: 6.2500e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9472 - loss: 0.6266 - precision: 0.9514 - recall: 0.9403  \n",
      "Epoch 60: val_accuracy did not improve from 0.88401\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9472 - loss: 0.6266 - precision: 0.9515 - recall: 0.9403 - val_accuracy: 0.8495 - val_loss: 0.9513 - val_precision: 0.8540 - val_recall: 0.8433 - learning_rate: 6.2500e-05 - lr: 3.1250e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9631 - loss: 0.5935 - precision: 0.9685 - recall: 0.9566  \n",
      "Epoch 61: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9630 - loss: 0.5936 - precision: 0.9684 - recall: 0.9565 - val_accuracy: 0.8527 - val_loss: 0.8637 - val_precision: 0.8576 - val_recall: 0.8495 - learning_rate: 3.1250e-05 - lr: 3.1250e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9686 - loss: 0.5855 - precision: 0.9711 - recall: 0.9650  \n",
      "Epoch 62: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9684 - loss: 0.5857 - precision: 0.9709 - recall: 0.9647 - val_accuracy: 0.8558 - val_loss: 0.8749 - val_precision: 0.8632 - val_recall: 0.8307 - learning_rate: 3.1250e-05 - lr: 3.1250e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9570 - loss: 0.5934 - precision: 0.9671 - recall: 0.9470  \n",
      "Epoch 63: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9570 - loss: 0.5936 - precision: 0.9670 - recall: 0.9470 - val_accuracy: 0.8370 - val_loss: 0.8878 - val_precision: 0.8516 - val_recall: 0.8276 - learning_rate: 3.1250e-05 - lr: 3.1250e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9417 - loss: 0.6132 - precision: 0.9496 - recall: 0.9378  \n",
      "Epoch 64: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9418 - loss: 0.6131 - precision: 0.9497 - recall: 0.9379 - val_accuracy: 0.8652 - val_loss: 0.8013 - val_precision: 0.8754 - val_recall: 0.8589 - learning_rate: 3.1250e-05 - lr: 3.1250e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9524 - loss: 0.5931 - precision: 0.9560 - recall: 0.9476  \n",
      "Epoch 65: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9525 - loss: 0.5928 - precision: 0.9561 - recall: 0.9477 - val_accuracy: 0.8558 - val_loss: 0.8513 - val_precision: 0.8635 - val_recall: 0.8527 - learning_rate: 3.1250e-05 - lr: 3.1250e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9597 - loss: 0.5853 - precision: 0.9641 - recall: 0.9532  \n",
      "Epoch 66: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9595 - loss: 0.5853 - precision: 0.9640 - recall: 0.9531 - val_accuracy: 0.8589 - val_loss: 0.8645 - val_precision: 0.8658 - val_recall: 0.8495 - learning_rate: 3.1250e-05 - lr: 3.1250e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9499 - loss: 0.6039 - precision: 0.9514 - recall: 0.9444  \n",
      "Epoch 67: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9500 - loss: 0.6034 - precision: 0.9516 - recall: 0.9445 - val_accuracy: 0.8715 - val_loss: 0.8670 - val_precision: 0.8766 - val_recall: 0.8683 - learning_rate: 3.1250e-05 - lr: 3.1250e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9486 - loss: 0.5808 - precision: 0.9537 - recall: 0.9444  \n",
      "Epoch 68: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9487 - loss: 0.5805 - precision: 0.9538 - recall: 0.9444 - val_accuracy: 0.8307 - val_loss: 0.9532 - val_precision: 0.8333 - val_recall: 0.8150 - learning_rate: 3.1250e-05 - lr: 3.1250e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9530 - loss: 0.5823 - precision: 0.9603 - recall: 0.9483  \n",
      "Epoch 69: val_accuracy did not improve from 0.88401\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9532 - loss: 0.5821 - precision: 0.9605 - recall: 0.9484 - val_accuracy: 0.8589 - val_loss: 0.8538 - val_precision: 0.8686 - val_recall: 0.8495 - learning_rate: 3.1250e-05 - lr: 1.5625e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9683 - loss: 0.5609 - precision: 0.9719 - recall: 0.9620  \n",
      "Epoch 70: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9681 - loss: 0.5610 - precision: 0.9718 - recall: 0.9618 - val_accuracy: 0.8589 - val_loss: 0.9110 - val_precision: 0.8631 - val_recall: 0.8495 - learning_rate: 1.5625e-05 - lr: 1.5625e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9701 - loss: 0.5330 - precision: 0.9743 - recall: 0.9673  \n",
      "Epoch 71: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9699 - loss: 0.5334 - precision: 0.9741 - recall: 0.9671 - val_accuracy: 0.8433 - val_loss: 0.9198 - val_precision: 0.8494 - val_recall: 0.8307 - learning_rate: 1.5625e-05 - lr: 1.5625e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9464 - loss: 0.5711 - precision: 0.9540 - recall: 0.9414  \n",
      "Epoch 72: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9465 - loss: 0.5712 - precision: 0.9540 - recall: 0.9414 - val_accuracy: 0.8370 - val_loss: 0.9258 - val_precision: 0.8418 - val_recall: 0.8339 - learning_rate: 1.5625e-05 - lr: 1.5625e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9396 - loss: 0.5722 - precision: 0.9484 - recall: 0.9388  \n",
      "Epoch 73: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9397 - loss: 0.5721 - precision: 0.9484 - recall: 0.9389 - val_accuracy: 0.8746 - val_loss: 0.8089 - val_precision: 0.8850 - val_recall: 0.8683 - learning_rate: 1.5625e-05 - lr: 1.5625e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9674 - loss: 0.5512 - precision: 0.9728 - recall: 0.9607  \n",
      "Epoch 74: val_accuracy did not improve from 0.88401\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.9673 - loss: 0.5513 - precision: 0.9726 - recall: 0.9607 - val_accuracy: 0.8621 - val_loss: 0.8500 - val_precision: 0.8667 - val_recall: 0.8558 - learning_rate: 1.5625e-05 - lr: 7.8125e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9521 - loss: 0.5549 - precision: 0.9574 - recall: 0.9495  \n",
      "Epoch 75: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.9521 - loss: 0.5549 - precision: 0.9574 - recall: 0.9495 - val_accuracy: 0.8339 - val_loss: 0.8836 - val_precision: 0.8349 - val_recall: 0.8245 - learning_rate: 7.8125e-06 - lr: 7.8125e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9750 - loss: 0.5294 - precision: 0.9786 - recall: 0.9709  \n",
      "Epoch 76: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.9749 - loss: 0.5295 - precision: 0.9785 - recall: 0.9708 - val_accuracy: 0.8464 - val_loss: 0.8518 - val_precision: 0.8558 - val_recall: 0.8370 - learning_rate: 7.8125e-06 - lr: 7.8125e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9677 - loss: 0.5421 - precision: 0.9689 - recall: 0.9657  \n",
      "Epoch 77: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9676 - loss: 0.5421 - precision: 0.9688 - recall: 0.9655 - val_accuracy: 0.8746 - val_loss: 0.8293 - val_precision: 0.8875 - val_recall: 0.8652 - learning_rate: 7.8125e-06 - lr: 7.8125e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9536 - loss: 0.5556 - precision: 0.9578 - recall: 0.9523  \n",
      "Epoch 78: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9536 - loss: 0.5555 - precision: 0.9578 - recall: 0.9522 - val_accuracy: 0.8433 - val_loss: 0.8767 - val_precision: 0.8476 - val_recall: 0.8370 - learning_rate: 7.8125e-06 - lr: 7.8125e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9427 - loss: 0.5811 - precision: 0.9529 - recall: 0.9376  \n",
      "Epoch 79: val_accuracy did not improve from 0.88401\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9431 - loss: 0.5803 - precision: 0.9531 - recall: 0.9379 - val_accuracy: 0.8621 - val_loss: 0.8204 - val_precision: 0.8774 - val_recall: 0.8527 - learning_rate: 7.8125e-06 - lr: 3.9063e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9710 - loss: 0.5196 - precision: 0.9735 - recall: 0.9696  \n",
      "Epoch 80: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9709 - loss: 0.5199 - precision: 0.9734 - recall: 0.9695 - val_accuracy: 0.8558 - val_loss: 0.8101 - val_precision: 0.8612 - val_recall: 0.8558 - learning_rate: 3.9063e-06 - lr: 3.9063e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9620 - loss: 0.5399 - precision: 0.9631 - recall: 0.9579  \n",
      "Epoch 81: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9620 - loss: 0.5400 - precision: 0.9631 - recall: 0.9578 - val_accuracy: 0.8495 - val_loss: 0.8363 - val_precision: 0.8508 - val_recall: 0.8401 - learning_rate: 3.9063e-06 - lr: 3.9063e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9542 - loss: 0.5638 - precision: 0.9568 - recall: 0.9475  \n",
      "Epoch 82: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9544 - loss: 0.5636 - precision: 0.9570 - recall: 0.9478 - val_accuracy: 0.8495 - val_loss: 0.8361 - val_precision: 0.8603 - val_recall: 0.8495 - learning_rate: 3.9063e-06 - lr: 3.9063e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9745 - loss: 0.5182 - precision: 0.9751 - recall: 0.9683  \n",
      "Epoch 83: val_accuracy did not improve from 0.88401\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9745 - loss: 0.5183 - precision: 0.9750 - recall: 0.9683 - val_accuracy: 0.8652 - val_loss: 0.8802 - val_precision: 0.8738 - val_recall: 0.8464 - learning_rate: 3.9063e-06 - lr: 3.9063e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9682 - loss: 0.5267 - precision: 0.9754 - recall: 0.9665  \n",
      "Epoch 84: val_accuracy did not improve from 0.88401\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9682 - loss: 0.5270 - precision: 0.9753 - recall: 0.9664 - val_accuracy: 0.8245 - val_loss: 0.8937 - val_precision: 0.8307 - val_recall: 0.8150 - learning_rate: 3.9063e-06 - lr: 1.9531e-06\n",
      "Epoch 84: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr, lr_tracker] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b5d1cff-5fc1-4ea6-b9bd-b1b8ab8adeb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ✅ Extract Metrics from Training History\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m history_dict \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m      6\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(history_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# ✅ Calculate Error Rate\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Extract Metrics from Training History\n",
    "history_dict = history.history\n",
    "epochs = range(1, len(history_dict['loss']) + 1)\n",
    "\n",
    "# ✅ Calculate Error Rate\n",
    "train_error_rate = [1 - acc for acc in history_dict['accuracy']]\n",
    "val_error_rate = [1 - acc for acc in history_dict['val_accuracy']]\n",
    "\n",
    "# ✅ Create Subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))  # 3 Rows, 2 Columns\n",
    "fig.suptitle(\"Training Performance Metrics\", fontsize=14)\n",
    "\n",
    "# 🎯 Plot 1: Training & Validation Accuracy\n",
    "axes[0, 0].plot(epochs, history_dict['accuracy'], 'b-', label='Test Accuracy')\n",
    "axes[0, 0].plot(epochs, history_dict['val_accuracy'], 'r-', label='Training and Validation Accuracy')\n",
    "axes[0, 0].set_title(\"Test Accuracy\")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 📉 Plot 2: Training & Validation Loss\n",
    "axes[0, 1].plot(epochs, history_dict['loss'], 'b-', label='Training Loss')\n",
    "axes[0, 1].plot(epochs, history_dict['val_loss'], 'r-', label='Validation Loss')\n",
    "axes[0, 1].set_title(\"Test Loss\")\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 🎯 Plot 3: Precision\n",
    "if 'precision' in history_dict:\n",
    "    axes[1, 0].plot(epochs, history_dict['precision'], 'b-', label='Test Precision')\n",
    "    axes[1, 0].plot(epochs, history_dict['val_precision'], 'r-', label='Training and Validation Precision')\n",
    "    axes[1, 0].set_title(\"Test Precision\")\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# 🎯 Plot 4: Recall\n",
    "if 'recall' in history_dict:\n",
    "    axes[1, 1].plot(epochs, history_dict['recall'], 'b-', label='Test Recall')\n",
    "    axes[1, 1].plot(epochs, history_dict['val_recall'], 'r-', label='Training and Validation Recall')\n",
    "    axes[1, 1].set_title(\"Test Recall\")\n",
    "    axes[1, 1].legend()\n",
    "\n",
    "# 🎯 Plot 5: Error Rate\n",
    "axes[2, 0].plot(epochs, train_error_rate, 'b-', label='Test Error Rate')\n",
    "axes[2, 0].plot(epochs, val_error_rate, 'r-', label='Training and Validation Error Rate')\n",
    "axes[2, 0].set_title(\"Test Error Rate\")\n",
    "axes[2, 0].legend()\n",
    "\n",
    "# 🎯 Plot 6: Learning Rate (If ReduceLROnPlateau Used)\n",
    "if 'lr' in history_dict:\n",
    "    axes[2, 1].plot(epochs, history_dict['lr'], 'b-', label='Learning Rate')\n",
    "    axes[2, 1].set_title(\"Learning Rate\")\n",
    "    axes[2, 1].legend()\n",
    "\n",
    "# ✅ Adjust Layout & Show Plots\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "039fae2e-4311-468a-8d88-71f422405cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Accuracy Statistics:\n",
      "🔹 Training - Max: 97.34%, Min: 59.69%, Avg: 87.15%\n",
      "🔹 Validation - Max: 88.40%, Min: 25.08%, Avg: 72.69%\n",
      "\n",
      "📊 Loss Statistics:\n",
      "🔹 Training - Max: 3.05, Min: 0.52, Avg: 1.11\n",
      "🔹 Validation - Max: 9.12, Min: 0.80, Avg: 1.65\n",
      "\n",
      "📊 Precision Statistics:\n",
      "🔹 Training - Max: 97.63%, Min: 61.17%, Avg: 88.40%\n",
      "🔹 Validation - Max: 89.90%, Min: 25.08%, Avg: 73.96%\n",
      "\n",
      "📊 Recall Statistics:\n",
      "🔹 Training - Max: 96.88%, Min: 57.34%, Avg: 85.70%\n",
      "🔹 Validation - Max: 86.83%, Min: 25.08%, Avg: 70.98%\n",
      "\n",
      "📉 Learning Rate - Max: 0.00100000, Min: 0.00000195, Avg: 0.00039711\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract history data\n",
    "train_acc = np.array(history.history['accuracy']) * 100\n",
    "val_acc = np.array(history.history['val_accuracy']) * 100\n",
    "train_loss = np.array(history.history['loss'])\n",
    "val_loss = np.array(history.history['val_loss'])\n",
    "train_precision = np.array(history.history.get('precision', [])) * 100\n",
    "val_precision = np.array(history.history.get('val_precision', [])) * 100\n",
    "train_recall = np.array(history.history.get('recall', [])) * 100\n",
    "val_recall = np.array(history.history.get('val_recall', [])) * 100\n",
    "learning_rates = np.array(history.history.get('lr', []))\n",
    "\n",
    "# Function to display min, max, and average\n",
    "def display_stats(metric_name, train_values, val_values=None, is_percentage=False):\n",
    "    scale = 1 if not is_percentage else 100\n",
    "    unit = \"%\" if is_percentage else \"\"\n",
    "    \n",
    "    print(f\"\\n📊 {metric_name} Statistics:\")\n",
    "    print(f\"🔹 Training - Max: {np.max(train_values):.2f}{unit}, Min: {np.min(train_values):.2f}{unit}, Avg: {np.mean(train_values):.2f}{unit}\")\n",
    "    \n",
    "    if val_values is not None and len(val_values) > 0:\n",
    "        print(f\"🔹 Validation - Max: {np.max(val_values):.2f}{unit}, Min: {np.min(val_values):.2f}{unit}, Avg: {np.mean(val_values):.2f}{unit}\")\n",
    "\n",
    "# Display statistics for each metric\n",
    "display_stats(\"Accuracy\", train_acc, val_acc, is_percentage=True)\n",
    "display_stats(\"Loss\", train_loss, val_loss)\n",
    "\n",
    "if len(train_precision) > 0:\n",
    "    display_stats(\"Precision\", train_precision, val_precision, is_percentage=True)\n",
    "\n",
    "if len(train_recall) > 0:\n",
    "    display_stats(\"Recall\", train_recall, val_recall, is_percentage=True)\n",
    "\n",
    "if len(learning_rates) > 0:\n",
    "    print(f\"\\n📉 Learning Rate - Max: {np.max(learning_rates):.8f}, Min: {np.min(learning_rates):.8f}, Avg: {np.mean(learning_rates):.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2af6025-841b-4232-b836-2bc3cd96c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# ✅ Load the Best Model\n",
    "model_path = \"best_model.keras\"  # Update this if needed\n",
    "model = load_model(model_path)\n",
    "\n",
    "# ✅ Define Class Labels (Make sure they match the training order)\n",
    "class_labels = ['Blotch_Apple', 'Normal_Apple', 'Rot_Apple', 'Scab_Apple']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6c53939-8677-40e5-a7a6-9b794d8b02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\" Load and preprocess image for model prediction. \"\"\"\n",
    "    img = cv2.imread(image_path)  # Load Image\n",
    "    img = cv2.resize(img, (150, 150))  # Resize to match training size\n",
    "    img = img / 255.0  # Normalize Pixel Values\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66e9bf27-b5a6-4ea6-80e5-36750f14f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    \"\"\" Predict class of an image. \"\"\"\n",
    "    processed_img = preprocess_image(image_path)\n",
    "    prediction = model.predict(processed_img)\n",
    "    \n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]  # Get highest probability index\n",
    "    confidence = np.max(prediction) * 100  # Convert to percentage\n",
    "    \n",
    "    print(f\"🖼️ Predicted Class: {class_labels[predicted_class]} ({confidence:.2f}%)\")\n",
    "    return class_labels[predicted_class], confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a80b38b3-1354-4ff7-9db9-a3fc1dac20cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "🖼️ Predicted Class: Scab_Apple (94.47%)\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\fyp2\\datasets\\apple_disease_classification\\Test\\Normal_Apple\\AnyConv.com__images (25).jpg\"# Change to your image path\n",
    "predicted_class, confidence = predict_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e33ed2c-8d66-4382-bb5c-75837003df66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">18,940,416</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │      \u001b[38;5;34m18,940,416\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m2,052\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,113,038</span> (217.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,113,038\u001b[0m (217.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,037,188</span> (72.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,037,188\u001b[0m (72.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> (5.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,472\u001b[0m (5.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,074,378</span> (145.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m38,074,378\u001b[0m (145.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name: conv2d, Output Shape: (None, 148, 148, 32)\n",
      "Layer Name: batch_normalization, Output Shape: (None, 148, 148, 32)\n",
      "Layer Name: max_pooling2d, Output Shape: (None, 74, 74, 32)\n",
      "Layer Name: dropout, Output Shape: (None, 74, 74, 32)\n",
      "Layer Name: conv2d_1, Output Shape: (None, 72, 72, 64)\n",
      "Layer Name: batch_normalization_1, Output Shape: (None, 72, 72, 64)\n",
      "Layer Name: max_pooling2d_1, Output Shape: (None, 36, 36, 64)\n",
      "Layer Name: dropout_1, Output Shape: (None, 36, 36, 64)\n",
      "Layer Name: conv2d_2, Output Shape: (None, 34, 34, 128)\n",
      "Layer Name: batch_normalization_2, Output Shape: (None, 34, 34, 128)\n",
      "Layer Name: max_pooling2d_2, Output Shape: (None, 17, 17, 128)\n",
      "Layer Name: dropout_2, Output Shape: (None, 17, 17, 128)\n",
      "Layer Name: flatten, Output Shape: (None, 36992)\n",
      "Layer Name: dense, Output Shape: (None, 512)\n",
      "Layer Name: batch_normalization_3, Output Shape: (None, 512)\n",
      "Layer Name: dropout_3, Output Shape: (None, 512)\n",
      "Layer Name: dense_1, Output Shape: (None, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print model summary with detailed output shapes\n",
    "model.summary()\n",
    "\n",
    "# Correct way to get layer names and shapes dynamically\n",
    "for layer in model.layers:\n",
    "    try:\n",
    "        print(f\"Layer Name: {layer.name}, Output Shape: {layer.output.shape}\")\n",
    "    except AttributeError:\n",
    "        print(f\"Layer Name: {layer.name}, Output Shape: Not Available (e.g., input layer)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fyp2_env)",
   "language": "python",
   "name": "fyp2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
